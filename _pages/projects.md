---
layout: archive
title: "Projects"
permalink: /projects/
author_profile: true
---

### Are Large Language Models Good at Simulating Human Samples? A Topic Study.
- **Advised by**: Dr. Emilio Ferrara
- **Duration**: 2023.08 - Present
- **Details**:
  - Initiate an in-depth exploration of the capabilities of Large Language Models (LLMs) to emulate human behaviors across attributes such as ideology, income, gender, age, and race. 
  - Employ controlled experiments to evaluate the efficacy of LLMs in mimicking humans. 
  - Through fine-tuning, strive to enhance the cross-survey performance of LLMs, aiming for a model that can better replicate human behavior.

### Multimodal Partisan Sentiment Framing in Inflation News Coverage
- **Advised by**: Dr. Mohammad Soleymani
- **Duration**: 2023.05 - Present
- **Details**:
  - Conduct a comprehensive study on inflation-related video content by leveraging both facial and text analysis. The aim is to unveil inherent network narratives and biases, highlighting the contrasting stances of major media outlets on the topic.
  - Lead the implementation of video preprocessing techniques, specifically using Pyannote-video and OpenFace2. These tools enable accurate deciphering of facial expressions and their correlation with underlying media biases.
  - Find that the sentiment derived from Action Units consistently aligns with results from text analysis, indicating biases in FOX News and MSNBC, while CNN maintains relative balance.

### Classification of Political Extremists and Moderate Users on Twitter
- **Advised by**: Dr. Emilio Ferrara
- **Duration**: 2023.03 - Present
- **Details**:
  - Introduced a pioneering methodology, False-Supervised Learning, aimed at  classifying Twitter users based on political leanings and distinguishing between extremist and moderate stances.
  - Users are categorized as extremist or moderate using derived ideological scores. Transformer-based models are subsequently trained on various proportion splits of this labeled data.
  - The most precise model in differentiating between moderate and extremist ideologies is selected as the optimal approach. This refined model provides a more apparent ideological threshold.

### Retrieving False Claims on Twitter during the Russia-Ukraine Conflict
- **Advised by**: Dr. Emilio Ferrara
- **Duration**: 2022.06 - 2023.03
- **Details**:
  - Collected and manually annotated 83 false claims circulated on Twitter during the initial weeks of the Russia-Ukraine Conflict. This task involved handling and categorizing 5,872 original tweets into four distinct classes: related, not related, support, and refute.
  - Designed and implemented a transformer-based automated pipeline capable of detecting and retrieving tweets that discussed the identified false claims. This model achieved an F1-score of 80.57%. Further, the tweet retrieval model obtained a Top-3 accuracy of 96.35%.
  - Successfully demonstrated the practicality and effectiveness of the developed approach in retrieving false claims. The model showed consistent performance in real-world conditions.
