---
layout: archive
title: ""
permalink: /projects/
author_profile: true
---
Projects
======
## [Are Large Language Models Good at Simulating Human Samples? A Topic Study.]
- **Advised by**: Dr. Emilio Ferrara
- **Duration**: 2023.08 - Present
- **Details**:
  - This project aims to comprehensively explore the capabilities of Large Language Models (LLMs) in simulating human behaviors by providing them with a range of attributes, including ideology, politics, income, gender, age, and race.
  - To achieve this objective, a rigorous methodology involving controlled experiments will be implemented.
  - This project holds substantial significance in unraveling the intricacies of LLMs' ability to emulate human behaviors.

## [Multimodal Partisan Sentiment Framing in Inflation News Coverage]
- **Advised by**: Dr. Mohammad Soleymani and Dr. Meiqing Zhang
- **Duration**: 2023.05 - Present
- **Details**:
  - Embarked on a comprehensive examination of partisan biases in inflation news coverage across multimodal media channels. This research entailed a deep dive into how various media outlets, with different political leanings, chose to select and present information about inflation.
  - Executed a detailed multimodal content analysis on a variety of sources, including newspaper editorials, cable television transcripts, and video clips from January 2020 to December 2022.
  - Initial findings revealed significant differences in partisan emotion framing between television news and newspapers. The presence of stronger partisan cues leads to greater emotionality, and extremity, revealing the pivotal role emotion framing plays in shaping partisan narratives.

## [Classification of Political Extremists and Moderate Users on Twitter]
- **Advised by**: Dr. Emilio Ferrara and Dr. Luca Luceri
- **Duration**: 2023.03 - Present
- **Details**:
  - Pioneered a novel methodology, False-Supervised Learning, to accurately classify Twitter users based on their political leanings, distinguishing between extremist and moderate users.
  - Through this innovative technique, extremist or moderate labels are attributed to users according to their ideological scores. A distinct BERT classification model is trained and fine-tuned for each proportion split using the labeled data.
  - The model demonstrating superior precision in distinguishing between moderate and extremist ideologies is chosen as the optimal solution. This model will help define an ideological threshold, effectively categorizing users into the respective ideological categories.

## [Retrieving False Claims on Twitter during the Russia-Ukraine Conflict]
- **Advised by**: Dr. Emilio Ferrara and Dr. Luca Luceri
- **Duration**: 2022.06 - 2023.03
- **Details**:
  - Collected and manually annotated 83 false claims circulated on Twitter during the initial weeks of the Russia-Ukraine Conflict. This task involved handling and categorizing 5,872 original tweets into four distinct classes: related, not related, support, and refute.
  - Designed and implemented a transformer-based automated pipeline capable of detecting and retrieving tweets that discussed the identified false claims. This model achieved an F1-score of 80.57%. Further, the tweet retrieval model obtained a Top-3 accuracy of 96.35%.
  - Successfully demonstrated the practicality and effectiveness of the developed approach in retrieving false claims. The model showed consistent performance in real-world conditions.
