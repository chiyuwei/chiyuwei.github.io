---
layout: archive
title: "Projects"
permalink: /projects/
author_profile: true
---

### Are Large Language Models Good at Simulating Human Samples? A Topic Study.
- **Advised by**: Dr. Emilio Ferrara
- **Duration**: 2023.08 - Present
- **Details**:
  - This project aims to comprehensively explore the capabilities of Large Language Models (LLMs) in simulating human behaviors by providing them with a range of attributes, including ideology, politics, income, gender, age, and race.
  - To achieve this objective, a rigorous methodology involving controlled experiments will be implemented.
  - This project holds substantial significance in unraveling the intricacies of LLMs' ability to emulate human behaviors.

### Multimodal Partisan Sentiment Framing in Inflation News Coverage
- **Advised by**: Dr. Mohammad Soleymani and Dr. Meiqing Zhang
- **Duration**: 2023.05 - Present
- **Details**:
  - Conduct a comprehensive study on inflation-related video content by leveraging both facial and text analysis. The aim is to unveil inherent network narratives and biases, highlighting the contrasting stances of major media outlets on the topic.
  - Lead the implementation of video preprocessing techniques, specifically using Pyannote-video and OpenFace2. These tools enable accurate deciphering of facial expressions and their correlation with underlying media biases.
  - Find that the sentiment derived from Action Units consistently aligns with results from text analysis, indicating biases in FOX News and MSNBC, while CNN maintains relative balance.

### Classification of Political Extremists and Moderate Users on Twitter
- **Advised by**: Dr. Emilio Ferrara and Dr. Luca Luceri
- **Duration**: 2023.03 - Present
- **Details**:
  - Introduced a pioneering methodology, False-Supervised Learning, aimed at  classifying Twitter users based on political leanings and distinguishing between extremist and moderate stances.
  - Users are categorized as extremist or moderate using derived ideological scores. Transformer-based models are subsequently trained on various proportion splits of this labeled data.
  - The most precise model in differentiating between moderate and extremist ideologies is selected as the optimal approach. This refined model provides a more apparent ideological threshold.

### Retrieving False Claims on Twitter during the Russia-Ukraine Conflict
- **Advised by**: Dr. Emilio Ferrara and Dr. Luca Luceri
- **Duration**: 2022.06 - 2023.03
- **Details**:
  - Collected and manually annotated 83 false claims circulated on Twitter during the initial weeks of the Russia-Ukraine Conflict. This task involved handling and categorizing 5,872 original tweets into four distinct classes: related, not related, support, and refute.
  - Designed and implemented a transformer-based automated pipeline capable of detecting and retrieving tweets that discussed the identified false claims. This model achieved an F1-score of 80.57%. Further, the tweet retrieval model obtained a Top-3 accuracy of 96.35%.
  - Successfully demonstrated the practicality and effectiveness of the developed approach in retrieving false claims. The model showed consistent performance in real-world conditions.
